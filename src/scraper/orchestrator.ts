// src/scraper/orchestrator.ts
import { scrapeBoi, scrapeVaca, scrapeMilho, scrapeSoja } from './scot';
import { scrapeNoticiasAgricolas } from './noticias-agricolas';
import { 
  extractReferenceDate, 
  getExistingLocations, 
  filterComplementaryData, 
  validateTemporalConsistency,
  type PriceData 
} from './temporal-consistency';
import { saveData } from './persistence';

export async function executePrimarySource(): Promise<PriceData[]> {
  console.log('üéØ Executando scrapers prim√°rios (ScotConsultoria)');
  
  const allData: PriceData[] = [];
  
  try {
    // Executar todos os scrapers do Scot
    await scrapeBoi();
    await scrapeVaca(); 
    await scrapeMilho();
    await scrapeSoja();
    
    // Buscar dados rec√©m inseridos para retornar
    // (aqui voc√™ pode buscar do banco se necess√°rio, 
    // ou modificar os scrapers para retornar os dados)
    
    console.log('‚úÖ Scrapers prim√°rios executados com sucesso');
    return allData;
    
  } catch (error) {
    console.error('‚ùå Erro nos scrapers prim√°rios:', error);
    throw error;
  }
}

export async function executeComplementarySource(primaryData: PriceData[]): Promise<void> {
  console.log('üîÑ Executando scraper complementar (Not√≠cias Agr√≠colas)');
  
  try {
    // 1. Extrair data de refer√™ncia dos dados prim√°rios
    const referenceDate = extractReferenceDate(primaryData);
    if (!referenceDate) {
      // Se n√£o temos dados prim√°rios, usar data atual
      const today = new Date().toISOString().split('T')[0];
      console.warn(`‚ö†Ô∏è Usando data atual como refer√™ncia: ${today}`);
      console.log('‚ÑπÔ∏è Executando scraper complementar sem filtros temporais');
    } else {
      console.log(`üìÖ Data de refer√™ncia extra√≠da: ${referenceDate}`);
    }

    // 2. Buscar dados do Not√≠cias Agr√≠colas
    const complementaryData = await scrapeNoticiasAgricolas();
    
    if (complementaryData.length === 0) {
      console.log('‚ÑπÔ∏è Nenhum dado encontrado no Not√≠cias Agr√≠colas');
      return;
    }

    console.log(`üìä Dados brutos do Not√≠cias Agr√≠colas: ${complementaryData.length}`);

    // 3. Se temos data de refer√™ncia, filtrar dados
    let validData = complementaryData;
    
    if (referenceDate) {
      // Buscar localiza√ß√µes j√° existentes
      const existingLocations = await getExistingLocations(referenceDate);
      console.log(`üìç Localiza√ß√µes existentes na data ${referenceDate}: ${existingLocations.size}`);
      
      // Filtrar dados complementares
      validData = filterComplementaryData(
        complementaryData,
        referenceDate,
        existingLocations
      );
    }

    if (validData.length === 0) {
      console.log('‚ÑπÔ∏è Nenhuma cota√ß√£o complementar v√°lida encontrada');
      return;
    }

    // 4. Validar consist√™ncia temporal
    const validation = validateTemporalConsistency(validData);
    if (!validation.isValid) {
      console.error('‚ùå Inconsist√™ncia temporal detectada:', validation.errors);
      return;
    }

    // 5. Salvar dados complementares
    await saveData(validData, 'noticias_agricolas');
    
    console.log(`‚úÖ Not√≠cias Agr√≠colas: ${validData.length} cota√ß√µes complementares salvas`);
    
  } catch (error) {
    console.error('‚ùå Erro no scraper complementar:', error);
    throw error;
  }
}

export async function executeDaily(): Promise<void> {
  console.log('üöÄ === Iniciando coleta di√°ria de cota√ß√µes ===');
  
  try {
    // 1. Executar scrapers prim√°rios
    const primaryData = await executePrimarySource();
    
    // 2. Executar scraper complementar
    await executeComplementarySource(primaryData);
    
    console.log('üéâ === Coleta di√°ria conclu√≠da com sucesso ===');
    
  } catch (error) {
    console.error('üí• === Erro na execu√ß√£o di√°ria ===', error);
    throw error;
  }
}